# Lab 5：缺页异常与 Fork 机制

!!! danger "DDL"

    **本实验尚未发布。**

    - 代码、报告：2025-12-09 23:59
    - 验收：2025-12-16 实验课

## 实验简介

在 Lab4 中，我们的内核已经能够运行用户态程序了。但目前，我们创建用户进程的方式是在**内核态**使用 `user_mode_thread()` 手动指定进程，它再调用 `copy_process()` 和 `load_elf_binary()` 复制当前进程并把整个 ELF 程序加载到新进程中。这样做带来的问题是：

- **效率低下**：每次创建新进程都要把整个用户态程序从内存复制一份，浪费时间和内存。
- **缺乏灵活性**：只能由内核手动指定进程，无法由用户程序动态创建新的进程，限制了系统的可扩展性。

为了解决这些问题，本次实验将实现**按需分页加载（demand paging）**和**进程 Fork **机制：

- **按需分页加载**：用户态程序的内存页只有在访问时才加载到内存中，避免了一次性加载整个程序带来的资源浪费。我们引入 VMA（Virtual Memory Area，虚拟内存区域）来描述用户态进程的内存布局，并在进程访问未映射的内存页时触发缺页异常，由内核动态加载所需的页面。
- **Fork 机制**：允许用户态程序通过系统调用创建新的进程。新进程将继承父进程的内存空间和状态。另外，我们引入写时拷贝（Copy-On-Write, COW），只有在子进程或父进程尝试修改内存页时才真正复制该页，从而提高了内存利用率和进程创建效率。

## Part 0：准备工作

### 更新代码

现在你位于 `lab4` 分支。你需要创建 `lab5` 分支，合并上游的代码：

```shell
git checkout -b lab5
git fetch upstream
git merge upstream/lab5
```

下面的合并说明供同学们解决合并冲突时参考：

- **新增实验相关文件**

- **对现有内核的修改点**


## Part 1：虚拟内存区域 (VMA)


### 引入 VMA

我们再来回忆一下之前的实验是如何管理虚拟内存的：

- 在 Lab4 中，每个进程都有自己的页表 (`task->pgd`)，它在 `copy_pgd()` 函数中被**深拷贝**初始化。页表中包含了用户空间和内核空间的所有映射。
- 加载用户态进程时，`load_elf_binary()` 会为 ELF 文件的各个段（以及用户态程序的堆栈）分配物理内存，并通过 `create_mapping()` 将各个段的地址空间直接映射到进程的页表中。
- 在此之后，进程的地址空间与映射将保持不变，直到进程退出时被 `free_pgd()` 释放。

现在，我们要实现**按需加载分页**，即把加载用户态程序内容的时刻**从创建时推迟到第一次访问时**，那么就要用一个新的数据结构来描述用户态进程的内存布局，这样才能在访问未映射的内存页时，知道该页是否能被映射、应该加载什么内容、权限是什么。这个数据结构就是 **VMA**。

!!! info "Linux 中的 VMA 设计"
    在 Linux 内核中，VMA 结构 (`struct vm_area_struct`)是虚拟内存管理的核心组成部分之一，**每个 VMA 描述了一段在虚拟地址空间中连续且具有相同属性的内存区域**，它可以是**文件** (file)、**匿名内存** (anonymous memory)、**交换空间** (swap space) 等。用户态程序对不属于任何 VMA 的地址进行访问是无效的，会引发段错误 (segmentation fault)。

    每个进程的 `task_struct` 都有一个地址空间管理结构 `struct mm_struct`，它维护了该进程的虚拟地址空间，包括所有的 VMA 列表。今天的应用程序体量可能很庞大，Linux 内核采用 Maple Tree 来高效地索引和查找 VMA。

    感兴趣的同学可以阅读下面的材料进一步了解。

    - Linux 中 VMA 的定义与设计：[linux/mm_types.h](https://elixir.bootlin.com/linux/v6.17/source/include/linux/mm_types.h#L815), [Process Addresses](https://docs.kernel.org/mm/process_addrs.html)
    - Linux 中管理 VMA 的实际挑战：[The Maple Tree, A Modern Data Structure for a Complex Problem](https://blogs.oracle.com/linux/the-maple-tree-a-modern-data-structure-for-a-complex-problem)

!!! example "动手做：查看进程的地址空间"

    为了让同学们对 VMA 有一个更直观的认识，请同学们在 Linux 下运行 `cat /proc/<pid>/maps` 命令，查看某个进程的地址空间布局（你可以在我们的容器环境下查看 PID=1 的进程，也可以自己任意挑选一个）。请你描述一下：

    - 输出内容中各列的含义分别是什么？你可以参考 [proc_pid_maps(5)](https://man7.org/linux/man-pages/man5/proc_pid_maps.5.html) 中的说明。
    - 挑选一些有代表的行，分析一下其中每一列值的具体内容及其含义。

### VMA 的设计

我们的设计基本遵循了 Linux 的思路，但做了许多简化。我们在原来的 `task_struct` 中新增了 `struct mm_struct mm` 成员，用于描述进程的地址空间。它主要包含了：

```c title="kernel/arch/riscv/include/proc.h"
struct mm_struct {
	pgd_t *pgd; /**< 根页表 */
	struct list_head mmap; /**< 虚拟内存区域链表 */
};
```

其中，**为了语义上的统一**，我们把 `pgd` 也移动到了 `mm_struct` 中。`mmap` 是一个双向链表，链表中的每个节点是一个 VMA，定义如下：

```c title="kernel/arch/riscv/include/vma.h"
struct vm_area_struct {
	struct list_head list;
	uint64_t vm_start; /**< 虚拟内存起始地址 */
	uint64_t vm_end;   /**< 虚拟内存结束地址 */
	uint64_t vm_flags; /**< 权限标志 */
	uint64_t vm_pgoff; /**< 偏移量 */
	uint64_t vm_filesz; /**< 文件大小 */
    void *vm_file; /**< 文件指针 */
};
```

每个 VMA 也有它的对应权限位，在我们的实验中只用到了 `R, W, X` 三个权限位，其定义也可以在 `vma.h` 中找到。

!!! note "关于虚拟内存区域"
    - 这里记录的 `vm_start` 和 `vm_end` 都是**用户态的虚拟地址**，VMA 只会对用户程序会用到的内存区域进行描述，并且内核不会将除了用户程序会用到的内存区域以外的部分添加成为 VMA。
    - 我们用 `vm_file` 标识了 VMA 映射的来源。如果一段内存中的内容是由**文件**映射的，当这样的内存的 VMA 产生了缺页异常，操作系统就会将文件中的对应内容加载入内存，然后修改当前进程的页表来让其能够用原来的地址访问文件内容；如果它不是由文件映射的，则有可能是一块**匿名**（anonymous）的区域（例如用户的栈空间，在 `proc/<pid>/maps` 中被标记为 `[stack]` 的部分），我们会为它直接分配一块新的物理内存页，并映射到对应的虚拟地址上。
    - VMA 中的权限位与页表项中的权限位是对应的，我们会根据 VMA 的权限来设置页表项的权限。但请注意，`vm_flags` 与 `PTE` 的 flags 并不完全相同，**同学们在实验中不能直接进行赋值**，而是需要手动进行转换。

### Task1：实现 VMA

- 实现 VMA 的创建与管理，见 `kernel/arch/riscv/kernel/vma.c`：

    - **我们提供** `vma_init()`, `copy_vma()` 和 `free_vma()` 三个函数，分别用于初始化、拷贝和释放进程的 VMA 链表。
    - **请你补全** `do_mmap()`。该函数接收一个进程的 `mm_struct` 以及一段虚拟地址范围和权限等信息，创建一个新的 VMA 并将其添加到进程的 VMA 链表中。
    - **请你补全** `find_vma()`。该函数接收一个进程的 `mm_struct` 以及一个虚拟地址，查找并返回包含该地址的 VMA。如果没有找到则返回 NULL。

- 相应地，你需要修改进程的生命周期管理，实现对 VMA 的维护，见 `kernel/arch/riscv/kernel/proc.c`：

    - **请你修改** `task_init()`, `copy_process()` 和 `release_task()` 函数，实现对 VMA 的初始化、拷贝和释放。
    - 另外，由于我们移动了 `pgd` 到 `mm_struct` 中，你还需要修改相关代码以适应这一变化。

!!! success "完成条件"

    完成该 Task 后，由于我们还没有实现按需分页加载，VMA 中其实不会有任何内容，程序应该和 Lab4 完成时一样正常运行。

    顺便提醒，由于现在的内核只能加载一个用户态的 ELF 程序，我们在 `kernel/user/src/main.c` 中同时提供了 Lab4 和 Lab5 的测试程序，你可以暂时修改 `#define LAB4_TEST 1` 来运行原先 Lab4 的用户态程序。


## Part 2：按需分页加载

### 按需加载的动机

我们在简介中已经提及，Lab4 实现的程序加载方式**效率低下**，因此我们需要引入**按需分页加载**的机制。但有同学可能会问：按需加载只是将加载时机从创建时推迟到了访问时，而且这种方式引入了工程上额外的复杂度，它真的是必要的吗？下面我们来分析一下按需加载的必要性。同学们可以思考一下下面两个场景：

- 今天我们的操作系统中可能同时运行着成百上千个进程，我们可以自由地在进程间切换，仿佛它们都在运行。而如果我们计算一下这些程序的总大小（可以想象一下如果我们需要把整个 OS 实验环境的镜像（它有 11GB 之大）加载入内存，还要同时运行浏览器访问实验文档、打开 VSCODE 编写代码），它已经远远超过了我们机器的物理内存大小了。如果我们仍然采用一次性加载的方式，那么我们根本无法同时运行这么多程序。
- 一个程序在运行过程中，**创建的内存空间往往远大于它实际使用的内存空间**。例如，一个程序可能会申请一个 1GB 的缓冲区用于处理数据，但在实际运行过程中，它可能只会使用其中的几 MB。采用一次性加载的方式会浪费大量的内存资源。

针对**第一个场景**，同学们可能已经在课上学习了虚拟内存中的**换页** (page swapping)机制。如果所有的进程都是必要的，那么当物理内存容量不够时，操作系统就会把若干物理页的内容写到类似于磁盘这种更低内存层级的存储介质中，然后回收这些物理页以供其他进程使用。由于我们目前的实验完全是 in memory 的，因此我们暂时不考虑换页机制。而针对**第二个场景**，**按需分页加载**就能很好地解决这个问题。

但无论上上述的哪一个机制，都离不开**缺页异常** (page fault) 的触发与处理，下面我们进行详细介绍。

### 缺页异常 Page Fault

现在我们已经完成了按需分页加载的准备工作———VMA 虚拟内存区域的设计与实现。那么，**按需加载**究竟是如何实现的呢？

同学们在调试之前实验的过程中一定遇到过类似下面的报错：

```text title="Trap Handler 捕获 Store Page Fault"
[ERR, PID = 1] trap.c:149:trap_handler: Unhandled trap: scause = Store/AMO page fault (0xf), sepc = 0xffffffd60020187c, stval = 0xffffffffffffffc0
```

这是由于在一个启用了虚拟内存的系统上，当正在运行的程序访问一个页表中没有映射的虚拟地址时，MMU 尝试通过页表进行映射，发现无法找到对应的物理地址，或者找到了物理地址，但是访问权限不够（例如对只读页进行写操作），就会触发一个**缺页异常（Page Fault）**。VMA 的引入让一个虚拟地址多了一种新的状态——**已分配但未映射**，可以想象的是，当我们实现用户态程序的按需加载，它在第一次访问某个地址时，由于页表项未映射，肯定也会触发缺页异常。

在 RISC-V 架构下，我们有如下三种缺页异常：

<div style="text-align: center" markdown="1">

| Interrupt | Exception Code | Description |
| :-: | :-: | --- |
| 0 | 12 | Instruction Page Fault |
| 0 | 13 | Load Page Fault |
| 0 | 15 | Store/AMO Page Fault |

</div>

在本次实验中，我们将在 `trap.c` 中实现 `do_page_fault()` 函数，它会捕获所有的缺页异常，并通过一些方式区分按需加载和非法访问的情况，并进行相应的处理。而区分方法也非常简单，那就是**检查缺页异常发生时的地址是否在某个 VMA 范围内**。如果在，就说明这是一个合法的按需加载请求，我们就根据 VMA 的信息来加载对应的页面；如果不在，就说明这是一个非法访问，我们就进行相应的错误处理。

### Task 2：实现缺页异常处理

<figure markdown="span">
    ![page_fault.drawio](lab5.assets/page_fault.drawio){ width="100" }
    <figcaption>
    缺页异常处理流程图
    </figcaption>
</figure>

- 实现缺页异常的捕获，见 `kernel/arch/riscv/kernel/trap.c`：
    - **请你修改** `trap_handler()` 函数，在捕获到缺页异常时调用 `do_page_fault()` 进行处理。
- 实现缺页异常的处理逻辑，见 `kernel/arch/riscv/kernel/fault.c`：
    - 请你根据上述的缺页异常处理流程，补全 `do_page_fault()` 函数，实现缺页异常的处理逻辑。
- 实现按需加载，见 `kernel/arch/riscv/kernel/binfmt_elf.c`：
    - **请你修改** `load_elf_binary()` 函数，使其**不再直接为 ELF 段分配物理内存和创建映射**，而是**为每个段创建对应的 VMA 并通过** `do_mmap()` **添加到进程的 VMA 链表中**。

!!! success "完成条件"

    完成该 Task 后，我们已经实现了按需分页加载的基本功能。程序应该和 Lab4 完成时一样正常运行。


## Part 3：Fork 机制

### 进程的创建：Fork

在 Lab2 中，我们已经在 [进程复制与加载](lab2.md#进程复制与加载) 一节中简单介绍了 Linux 中的进程创建方式，即通过 `fork()` 系统调用复制当前进程，创建一个新的子进程。子进程会继承父进程的内存空间和状态。

具体来说，当一个进程调用 `fork()` 时，内核会为该进程创建一个几乎一模一样的新进程，调用 fork 的进程一般被称为父进程，而新创建的进程被称为子进程。当 fork 完成，两个进程的**内存、寄存器、PC** 等状态都是一样的；但它们具有**不同的 PID 和虚拟地址空间**，在 fork 完成后会各自独立运行，互不干扰。

??? info "感受 fork 的威力，但是小心！"

    下面这一段 Shell 代码非常经典，就是著名的 Fork 炸弹，它会无限制地创建子进程，最终耗尽系统资源，导致系统崩溃。请**不要尝试在你的宿主机中或其他重要环境运行它**。你能想到它是如何不断创建子进程的吗？

    ```shell title="Fork Bomb 💣"
    :(){ :|:& };:
    ```

接下来，我们在上一节的基础上实现 fork 机制，允许用户态程序通过系统调用创建新的进程。我们先来思考一下 fork 调用之前和之后会发生什么。

- **调用之前**：fork 总是由父进程通过**系统调用**的方式发起，我们已经在 Lab4 中实现了系统调用的相关机制。
- **调用之后**：父进程沿着正常的系统调用路径结束 `do_fork()`，并返回子进程的 PID；子进程继承父进程的状态，被加入调度队列，就像其他进程一样等待被调度运行，并在被调度时开始执行并返回 0。

!!! note "fork 的接口定义"

    请同学们阅读 [fork(2) — Linux manual page](https://man7.org/linux/man-pages/man2/fork.2.html) 了解 fork 的接口定义与规范。

    事实上，fork 在实现上通过调用 `clone` 系统调用来完成，我们已经在内核态的 `sys_call_table` 中添加 `sys_clone()` 的映射，`syscall_handler()` 会在接收到对应的系统调用号时执行该函数（由于我们的简化实现，`sys_clone()` 其实就是 `do_fork()` 的一个 wrapper，我们在本次实验中只需要完成 fork 的实现）。

那么，`do_fork()` 具体应该做些什么呢？关键的有如下几点：

1. **创建新进程：**调用 `copy_process()` 创建一个新的 `task_struct`，它应该继承父进程的所有状态，包括寄存器、内存空间等。
2. **伪装成普通进程**：新进程的 `sp`, `ra` 等关键寄存器应该被设置为合适的值，使得它在被调度时能够像普通进程一样运行，而不是从 `do_fork()` 返回。
3. **返回值的设置**：父进程和子进程在 `fork()` 返回时应该有不同的值，父进程返回子进程的 PID，而子进程返回 0。

### Task 3：实现 Fork 机制

**请你完成** `kernel/arch/riscv/kernel/syscall.c` 中的 `do_fork()` 函数，实现 fork 机制。下面是对上述三点的具体说明：

对于**第一点**，如果你之前的实现正确，那么 `copy_process()` 已经帮助你完成了进程拷贝的全部工作。你只需要在 `do_fork()` 中调用它即可。为了帮助同学们确认这一点，下面是一些需要注意的点：

- 你需要**深拷贝**父进程的整个 `task_struct`，包括它的内核栈 `stack`、页表 `mm.pgd`、虚拟内存区域 `mm.mmap`。
- 你需要为新进程分配一个新的 PID，并将新进程添加到全局的进程列表 `task_list` 中。

对于**第二点**，情况略显复杂，需要同学们自己思考完成。以下是一些提示：

- 你需要**正确设置新进程的 `thread->sp, thread->ra`**。这很容易理解，因为新进程的第一次运行时刻是被调度器调度时，调度器通过 `switch_to()` 切换到新进程的 `ra` 和 `sp`，然后 `ret` 到 `ra` 指向的位置运行。

    !!! note "提示"

        **父子进程状态一致**，在 `do_fork()` 中，父进程**处于内核态**，且即将结束 `do_fork()` **从 trap 返回路径返回**。

- 你需要**正确设置新进程的 `sepc`**。这也很容易想到，因为**父子进程状态一致**，从 Lab4 我们已经知道系统调用返回时 `sepc` 应当指向 `ecall` 的下一条指令地址。

对于**第三点**，父进程返回子进程的 PID，我们直接通过设置 `do_fork()` 的返回值即可；而子进程返回 0，同学们需要找到合适的位置进行设置。

当我们按照顺序完成上述三点后，fork 的实现就完成了。

!!! note "继续思考"

    有同学可能会问，为什么只需要完成这三点就够了呢？我们可以多考虑一些细节：

    - **为什么不用设置 `sscratch` 和 `tp`？**因为 `tp` 就是当前进程 `current` 的指针，它指向 `task_struct`，我们只需要把 `task_struct` 加入调度队列即可，在 `__switch_to()` 中 `tp` 会被自动切换；而 `sscratch` 在内核态下被交换到 `tp` 中，并不会被使用到。
    - **为什么不用设置用户态的栈指针？**因为我们将在下面实现写时拷贝，父子进程的用户态栈空间在此时是共享的，而且父子进程状态一致，它们的栈指针应该指向同一位置。我们已经在 `copy_process()` 完成了内核栈的深拷贝，在 `pt_regs` 中的用户栈指针已经被正确设置。

!!! success "完成条件"

    完成该 Task 后，内核并不能正常运行。如果你运行 Lab 5 的测试代码，你会观察到一些灵车漂移的现象，你可以尝试分析其中的原因。


### 写时拷贝

早期的 fork 实现非常简单粗暴，子进程会将父进程的物理内存完整地拷贝一份，并映射到子进程的内存空间中，但事实上，这种方式在很多情况下是不必要的：

- 在上一节的描述中，我们已经提到，一个进程的地址空间往往大于它们运行时实际使用的地址空间，另外，有一部分虚拟内存（如外部库、代码段）都是只读的，因此拷贝整个地址空间会造成很大的浪费；
- 很多时候我们调用 fork 并不是为了复制当前进程，而是在接下来立刻调用 `exec()` 来加载一个新的程序，重置地址空间，那么之前的内存拷贝就完全没有意义了。

因此，我们可以通过写时拷贝 (COW) 的方式来优化 fork 的实现。写时拷贝的核心思想是进一步延后分配页面、拷贝内容的时机，**在 fork 时不立即复制父进程的内存页，而是让父子进程共享这些内存页，直到其中一个进程尝试修改某个内存页时，才真正地为该页创建一个副本**。它在提升 fork 性能的同时也减少了内存资源的消耗，是操作系统中一个很重要的优化。

那么，在实现上，我们怎么知道一个页需要写时拷贝，以及在什么时候进行拷贝呢？

- 根据上面的描述，我们知道：创建页的时机是**当某个进程尝试写入一个共享页时**，现在我们创建页都是在缺页异常处理时进行的，因此写时拷贝也应该在**缺页异常**中进行判断和处理。
- 而我们怎么样让进程尝试写入一个共享页时触发缺页异常呢？联想缺页异常发生的原因之一（想写入的地址存在，但是权限不够），我们可以**将进程的相关页表项设置为只读**，这样当进程尝试写入该页时，就会触发一个**Store Page Fault**，从而进入缺页异常处理流程。

<figure markdown="span">
    ![cow.drawio](lab5.assets/cow.drawio)
    <figcaption>
    写时拷贝机制示意图
    </figcaption>
</figure>


### Task 4：实现写时拷贝

**请你修改**下面两个函数，实现写时拷贝机制：

-  `kernel/arch/riscv/kernel/vm.c` 中的 `copy_pgd()` 函数；
-   `kernel/arch/riscv/kernel/fault.c` 中的 `do_page_fault()` 函数。

下面是对这两个函数实现的具体说明：

- **页表项设置**：我们在 `do_fork()` 中通过 `copy_process()` 的 `copy_pgd()` 函数来拷贝父进程的页表。现在，在拷贝页表项之前，我们需要**将父进程的相关页表项设置为只读**（清除 `PTE_W` 标志位），**然后再进行拷贝**。这样，我们将实现：
    - 父子进程的页表项都是只读的，且它们共享同一个物理页面；
    - 父子进程都可以正常读取该页面的内容，但当它们尝试写入该页面时，就会触发缺页异常。
- **缺页异常处理**：在 `do_page_fault()` 中，我们需要增加对写时拷贝的处理逻辑。当捕获到一个**合法的** Store Page Fault 时，我们需要**检查该地址对应的页表项是否是只读的**。如果是，我们就知道这是一个写时拷贝的请求，并可以**根据页面的引用计数**来决定是否需要创建一个新的物理页面：
    - 如果引用计数大于 1，说明还有其他进程也在使用该页面，我们需要**分配一个新的物理页面**，将原页面的内容复制到新页面中，然后**更新当前进程的页表项**，将该虚拟地址映射到新页面，并设置为可写。
    - 如果引用计数等于 1，说明只有当前进程在使用该页面，我们可以直接**将该页表项设置为可写**，而不需要进行页面复制。

!!! note "记得刷新 TLB！"

    需要注意的是，在这两处的实现中我们都有可能修改已映射的页表项，修改后需要**调用 `sfence.vma` 来刷新 TLB 缓存**。


!!! success "完成条件"

    **通过评测。**

    需要注意的是，我们最终的测试要求如下：

    - 在 `kernel/user/src/main.c` 中开启 Lab 5 的测试程序。
    ```c title="kernel/user/src/main.c"
    #define LAB4_TEST 0
    #define LAB5_TEST 1
    ```

    - 在 `kernel/arch/riscv/kernel/main.c` 中只手动创建两个进程。它们为 `PID=1` 的用户态进程和 `PID=2` 的 `kthreadd` 进程。
    ```c title="kernel/arch/riscv/kernel/main.c"
    user_mode_thread(_sramdisk); // Lab5 Test
	kernel_thread(kthreadd, NULL); // Lab2 Test3
	// user_mode_thread(_sramdisk); // Lab4 Test
	// kthread_create(test_sched, NULL); // Lab2 Test4
    ```

**恭喜你完成本学期操作系统实验正片的全部内容！**完结撒花 🎉


## 扩展阅读：Fork 是一个好的实现吗？

